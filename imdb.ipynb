{"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","gpuClass":"standard"},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Only the first 10k rows from the dataset are considered due to the system's handling capacity","metadata":{"id":"QmNaRD_H_Ssb"}},{"cell_type":"code","source":"from google.colab import drive \ndrive.mount('/content/drive/')","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Kr45NXe31XMD","outputId":"fb881204-2591-4edb-e9a9-7391042a70a7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":"Mounted at /content/drive/\n"}]},{"cell_type":"code","source":"import pandas as pd\nimport string\nimport re\nfrom tensorflow.keras.layers import Embedding, Dense, SimpleRNN","metadata":{"id":"Myo3qxKQ2nwu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv(\"/content/drive/MyDrive/IMDB Dataset.csv\") # reading the csv file\ndata.head()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"fVobXwZV2nte","outputId":"53b71e0d-bceb-486e-bf1e-24888f5efb80"},"execution_count":null,"outputs":[{"output_type":"execute_result","execution_count":4,"data":{"text/plain":["                                              review sentiment\n","0  One of the other reviewers has mentioned that ...  positive\n","1  A wonderful little production. <br /><br />The...  positive\n","2  I thought this was a wonderful way to spend ti...  positive\n","3  Basically there's a family where a little boy ...  negative\n","4  Petter Mattei's \"Love in the Time of Money\" is...  positive"],"text/html":["\n","  <div id=\"df-7de98850-9288-4fdc-9956-5d24569c18de\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>review</th>\n","      <th>sentiment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>One of the other reviewers has mentioned that ...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>I thought this was a wonderful way to spend ti...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Basically there's a family where a little boy ...</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n","      <td>positive</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7de98850-9288-4fdc-9956-5d24569c18de')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-7de98850-9288-4fdc-9956-5d24569c18de button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-7de98850-9288-4fdc-9956-5d24569c18de');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}}]},{"cell_type":"code","source":"data = data.iloc[0:10000] # taking the first 10k rows from the entire dataset, as a new dataframe\ndata.head()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"2bJm8jg82nr1","outputId":"81dc03a1-fb63-4599-ca5c-b0a71e0aec28"},"execution_count":null,"outputs":[{"output_type":"execute_result","execution_count":5,"data":{"text/plain":["                                              review sentiment\n","0  One of the other reviewers has mentioned that ...  positive\n","1  A wonderful little production. <br /><br />The...  positive\n","2  I thought this was a wonderful way to spend ti...  positive\n","3  Basically there's a family where a little boy ...  negative\n","4  Petter Mattei's \"Love in the Time of Money\" is...  positive"],"text/html":["\n","  <div id=\"df-2f10f752-890a-482c-87a1-7d5c671d2bee\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>review</th>\n","      <th>sentiment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>One of the other reviewers has mentioned that ...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>I thought this was a wonderful way to spend ti...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Basically there's a family where a little boy ...</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n","      <td>positive</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2f10f752-890a-482c-87a1-7d5c671d2bee')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-2f10f752-890a-482c-87a1-7d5c671d2bee button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-2f10f752-890a-482c-87a1-7d5c671d2bee');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}}]},{"cell_type":"code","source":"##function to preprocess the data.\ndef preprocess_data(review):\n    \n     \n    review = re.sub(r'</?\\s*br\\s*/?>', '', review)## to replace linebreak with a space\n    review = re.sub(r'([^\\w\\s])\\1+', r'\\1', review)### remove punctuations occuring multiple times together. Eg,'????','!!!!','......'\n    review = review.lower()  # Lower casing all the characters\n    review = re.sub(r'[^\\x00-\\x7F]+', '',review) # Replace all the characters except alphabets from the text\n    review = re.sub(r'\\'', '', review)\n    return review","metadata":{"id":"RfdMUOQM2noI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['review'] = data['review'].apply(lambda x: preprocess_data(x)) ##calling the preprocessing function through a lamda function\ndata['review']","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"74GHeSU-2nlV","outputId":"a2b10b3f-e37f-48ba-fd34-a353dd31bbe4"},"execution_count":null,"outputs":[{"output_type":"execute_result","execution_count":7,"data":{"text/plain":["0       one of the other reviewers has mentioned that ...\n","1       a wonderful little production. the filming tec...\n","2       i thought this was a wonderful way to spend ti...\n","3       basically theres a family where a little boy (...\n","4       petter matteis \"love in the time of money\" is ...\n","                              ...                        \n","9995    fun, entertaining movie about wwii german spy ...\n","9996    give me a break. how can anyone say that this ...\n","9997    this movie is a bad movie. but after watching ...\n","9998    this is a movie that was probably made to ente...\n","9999    smashing film about film-making. shows the int...\n","Name: review, Length: 10000, dtype: object"]},"metadata":{}}]},{"cell_type":"code","source":"\n# Import label encoder\nfrom sklearn import preprocessing\nimport tensorflow as tf\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.python import keras\nfrom tensorflow.python.keras.models import Sequential\nfrom tensorflow.python.keras.layers import Dense, Flatten, Dropout  \n\nlabel_encoder = preprocessing.LabelEncoder()\n  \n# Encode labels in column 'sentiment'\nsentiment = label_encoder.fit_transform(data['sentiment'])\n##label coded sentiment to one hot encoding\nsentiment =tf.keras.utils.to_categorical(sentiment)\n","metadata":{"id":"PKOUBPd72nio"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sentiment","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9MtwEpJH2nf3","outputId":"c882109f-ec7e-4fbc-cbd7-a189c87319b0"},"execution_count":null,"outputs":[{"output_type":"execute_result","execution_count":9,"data":{"text/plain":["array([[0., 1.],\n","       [0., 1.],\n","       [0., 1.],\n","       ...,\n","       [1., 0.],\n","       [1., 0.],\n","       [0., 1.]], dtype=float32)"]},"metadata":{}}]},{"cell_type":"code","source":"review=data['review'].tolist() # converting the 'review' to a list before tokenizing","metadata":{"id":"GgZ7Pze82ndL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vocab_size=4000 #initialising the number of unique words as vocab_size and the number of embedding input feature dimension\nembedding_dim=100","metadata":{"id":"wuPgVKRL2nae"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.text import Tokenizer\n\n# create tokenizer\ntokenizer = Tokenizer(num_words = vocab_size,oov_token=\"<OOV>\")\n\n# fit tokenizer on reviews\ntokenizer.fit_on_texts(review)\n\n# convert text to sequences of integers\nsequences = tokenizer.texts_to_sequences(review)\n\n# get max length of a sequence\nmax_length = max(len(seq) for seq in sequences)\n\n# perform zero padding in all the sequences in order to match the max length of the sequence\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\npadded_sequences = pad_sequences(sequences, padding='pre', maxlen=max_length)\n\nprint(padded_sequences)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"U-0aQ2lw2nXn","outputId":"2150fc62-4e92-4515-80ef-b3c3a8582e2e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":"[[   0    0    0 ...  122 3817  484]\n\n [   0    0    0 ... 2158   68  214]\n\n [   0    0    0 ...   63   16  340]\n\n ...\n\n [   0    0    0 ...   15  330  153]\n\n [   0    0    0 ...   49   17   70]\n\n [   0    0    0 ...    7  983 2682]]\n"}]},{"cell_type":"code","source":"X=padded_sequences","metadata":{"id":"deLVoEXa5I1l"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\n\ny=np.array(sentiment) # converting the one hot encoded sentiment to array to match the type of padded sequence","metadata":{"id":"kE9a8RDg4R7F"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_Train,X_Test,Y_Train,Y_Test=train_test_split(X,y,test_size=0.2,random_state=42) # train test split as 80-20\n\nX_Val,X_Test,Y_Val,Y_Test=train_test_split(X_Test,Y_Test,test_size=0.5,random_state=42) #test val split as 10-10","metadata":{"id":"VsK3aREA4Yr3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#printing the length of train,test,val data\nprint('X-train length',len(X_Train))\nprint('Y-train length',len(Y_Train))\nprint('X-testlength',len(X_Test))\nprint('Y-test length',len(Y_Test))\nprint('X-val length',len(X_Val))\nprint('Y-val length',len(Y_Val))\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HaPY2T0T4hZ7","outputId":"083a4715-14b9-44b6-c735-146a3a70da7f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":"X-train length 8000\n\nY-train length 8000\n\nX-testlength 1000\n\nY-test length 1000\n\nX-val length 1000\n\nY-val length 1000\n"}]},{"cell_type":"markdown","source":"## RNN","metadata":{"id":"mfJ6vNjs-FCu"}},{"cell_type":"code","source":"","metadata":{"id":"FjGc_BhF9NYO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# Define the model architecture with one embedding, RNN and fully connected layer\nmodel = Sequential()\nmodel.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_length))\nmodel.add(SimpleRNN(units=256, dropout = 0.2, activation='sigmoid')) # 256 is the number of neurons in the layer\nmodel.add(Dense(units=2, activation='sigmoid'))","metadata":{"id":"kHW9HWep9NUB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])## compiling the model with the optimizer,lossfunction ","metadata":{"id":"Gl4ERA0f9NP4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.fit(X_Train,Y_Train,validation_data=(X_Val,Y_Val), epochs=10, batch_size=128)#model fitting","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n2k2QToL9NL-","outputId":"34e0681b-1c7c-4350-cf06-b1455236ccc4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":"Epoch 1/10\n\n63/63 [==============================] - 167s 3s/step - loss: 0.7021 - accuracy: 0.5124 - val_loss: 0.6798 - val_accuracy: 0.5500\n\nEpoch 2/10\n\n63/63 [==============================] - 150s 2s/step - loss: 0.6465 - accuracy: 0.6376 - val_loss: 0.6475 - val_accuracy: 0.6110\n\nEpoch 3/10\n\n63/63 [==============================] - 149s 2s/step - loss: 0.5728 - accuracy: 0.6964 - val_loss: 0.6355 - val_accuracy: 0.6480\n\nEpoch 4/10\n\n63/63 [==============================] - 149s 2s/step - loss: 0.4954 - accuracy: 0.7540 - val_loss: 0.6326 - val_accuracy: 0.6570\n\nEpoch 5/10\n\n63/63 [==============================] - 148s 2s/step - loss: 0.4354 - accuracy: 0.7922 - val_loss: 0.7357 - val_accuracy: 0.6700\n\nEpoch 6/10\n\n63/63 [==============================] - 149s 2s/step - loss: 0.3784 - accuracy: 0.8275 - val_loss: 0.7142 - val_accuracy: 0.7020\n\nEpoch 7/10\n\n63/63 [==============================] - 149s 2s/step - loss: 0.3166 - accuracy: 0.8636 - val_loss: 0.6312 - val_accuracy: 0.7160\n\nEpoch 8/10\n\n63/63 [==============================] - 148s 2s/step - loss: 0.2824 - accuracy: 0.8830 - val_loss: 0.6761 - val_accuracy: 0.7120\n\nEpoch 9/10\n\n63/63 [==============================] - 147s 2s/step - loss: 0.2659 - accuracy: 0.8984 - val_loss: 0.7158 - val_accuracy: 0.7220\n\nEpoch 10/10\n\n63/63 [==============================] - 147s 2s/step - loss: 0.2080 - accuracy: 0.9224 - val_loss: 0.7264 - val_accuracy: 0.7340\n"},{"output_type":"execute_result","execution_count":18,"data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f83d7892950>"]},"metadata":{}}]},{"cell_type":"code","source":"loss, accuracy = model.evaluate(X_Test, Y_Test)##testing the model\nprint(\"Test Loss:\", loss)\nprint(\"Test Accuracy:\", accuracy)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wpFT05u39NIi","outputId":"89c4c002-d3bc-4e50-9215-f46444c8454a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":"32/32 [==============================] - 5s 169ms/step - loss: 0.6556 - accuracy: 0.7500\n\nTest Loss: 0.6556399464607239\n\nTest Accuracy: 0.75\n"}]},{"cell_type":"code","source":"from sklearn.metrics import precision_score, recall_score, f1_score\n\n# Get the predicted labels\ny_pred = model.predict(X_Test)\ny_pred = np.argmax(y_pred, axis=1)\n\n# Convert the one-hot encoded labels back to integers\ny_true = np.argmax(Y_Test, axis=1)\n\n# Calculate precision, recall, and F1-score\nprecision = precision_score(y_true, y_pred, average='binary')\nrecall = recall_score(y_true, y_pred, average='binary')\nf1 = f1_score(y_true, y_pred, average='binary')\n\nprint(\"Precision:\", precision)\nprint(\"Recall:\", recall)\nprint(\"F1-score:\", f1)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ALUseHvjAiTu","outputId":"3dba2db9-eb80-4e23-cb07-e88f453cc6f7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":"Precision: 0.7573385518590998\n\nRecall: 0.7543859649122807\n\nF1-score: 0.7558593750000001\n"}]},{"cell_type":"markdown","source":"## LSTM","metadata":{"id":"qYaKjCpG-B1w"}},{"cell_type":"code","source":"","metadata":{"id":"Haf__kKm9NFg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.layers import LSTM\n# Define the model architecture\nlstm_model = Sequential()\nlstm_model.add(Embedding(input_dim=4000, output_dim=100, input_length=max_length))\nlstm_model.add(LSTM(100))\nlstm_model.add(Dropout(0.2))\n\nlstm_model.add(Dense(units=2, activation='sigmoid'))\n\n\n","metadata":{"id":"-tk4v1Ha4hWV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Compile the model\nlstm_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])","metadata":{"id":"N4g6pCOz4hTa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lstm_model.fit(X_Train,Y_Train,validation_data=(X_Val,Y_Val), epochs=10, batch_size=128)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TKIIgeD64hRA","outputId":"ed455c7f-b0fb-4605-f54e-161ff0d1de28"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":"Epoch 1/10\n\n63/63 [==============================] - 424s 7s/step - loss: 0.6439 - accuracy: 0.6248 - val_loss: 0.5740 - val_accuracy: 0.7370\n\nEpoch 2/10\n\n63/63 [==============================] - 367s 6s/step - loss: 0.4325 - accuracy: 0.8173 - val_loss: 0.3797 - val_accuracy: 0.8400\n\nEpoch 3/10\n\n63/63 [==============================] - 362s 6s/step - loss: 0.2392 - accuracy: 0.9039 - val_loss: 0.3398 - val_accuracy: 0.8760\n\nEpoch 4/10\n\n63/63 [==============================] - 363s 6s/step - loss: 0.1944 - accuracy: 0.9265 - val_loss: 0.3809 - val_accuracy: 0.8440\n\nEpoch 5/10\n\n63/63 [==============================] - 365s 6s/step - loss: 0.1517 - accuracy: 0.9457 - val_loss: 0.3961 - val_accuracy: 0.8660\n\nEpoch 6/10\n\n63/63 [==============================] - 362s 6s/step - loss: 0.0955 - accuracy: 0.9711 - val_loss: 0.4579 - val_accuracy: 0.8570\n\nEpoch 7/10\n\n60/63 [===========================>..] - ETA: 16s - loss: 0.0616 - accuracy: 0.9836"}]},{"cell_type":"code","source":"loss, accuracy = lstm_model.evaluate(X_Test, Y_Test)\nprint(\"Test Loss:\", loss)\nprint(\"Test Accuracy:\", accuracy)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-JMuO3Tq4hOs","outputId":"16789f1a-759b-4bb0-84dd-3e903fb92c23"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":"32/32 [==============================] - 1s 22ms/step - loss: 0.5513 - accuracy: 0.8260\n\nTest Loss: 0.5513419508934021\n\nTest Accuracy: 0.8259999752044678\n"}]},{"cell_type":"code","source":"from sklearn.metrics import precision_score, recall_score, f1_score\n\n# Get the predicted labels\ny_pred = lstm_model.predict(X_Test)\ny_pred = np.argmax(y_pred, axis=1)\n\n# Convert the one-hot encoded labels back to integers\ny_true = np.argmax(Y_Test, axis=1)\n\n# Calculate precision, recall, and F1-score\nprecision = precision_score(y_true, y_pred, average='binary')\nrecall = recall_score(y_true, y_pred, average='binary')\nf1 = f1_score(y_true, y_pred, average='binary')\n\nprint(\"Precision:\", precision)\nprint(\"Recall:\", recall)\nprint(\"F1-score:\", f1)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f1qSjLqU8AVf","outputId":"34a4dc6f-0198-4eaa-dc0d-c4602d9da776"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":"Precision: 0.8480492813141683\n\nRecall: 0.8050682261208577\n\nF1-score: 0.8260000000000001\n"}]},{"cell_type":"markdown","source":"## GRU","metadata":{"id":"k5tdidvZ9632"}},{"cell_type":"code","source":"","metadata":{"id":"ZGXQ3MdQ8PJ5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.layers import  GRU\n# Define the model architecture\ngru_model = Sequential()\ngru_model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_length))\ngru_model.add(GRU(256))\ngru_model.add(Dense(units=2, activation='sigmoid'))\n\n# Compile the model\ngru_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n\n# Train the model\ngru_model.fit(X_Train,Y_Train,validation_data=(X_Val,Y_Val), epochs=10, batch_size=128)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Pl3c8x2E8PGv","outputId":"8acc9828-20f2-4096-f531-e2da504b8467"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":"Epoch 1/10\n\n63/63 [==============================] - 15s 190ms/step - loss: 0.6726 - accuracy: 0.6064 - val_loss: 0.5894 - val_accuracy: 0.7070\n\nEpoch 2/10\n\n63/63 [==============================] - 12s 186ms/step - loss: 0.4923 - accuracy: 0.7675 - val_loss: 0.5098 - val_accuracy: 0.7410\n\nEpoch 3/10\n\n63/63 [==============================] - 12s 188ms/step - loss: 0.3516 - accuracy: 0.8504 - val_loss: 0.4169 - val_accuracy: 0.8310\n\nEpoch 4/10\n\n63/63 [==============================] - 12s 192ms/step - loss: 0.2337 - accuracy: 0.9060 - val_loss: 0.4167 - val_accuracy: 0.8470\n\nEpoch 5/10\n\n63/63 [==============================] - 12s 192ms/step - loss: 0.1737 - accuracy: 0.9355 - val_loss: 0.4539 - val_accuracy: 0.8380\n\nEpoch 6/10\n\n63/63 [==============================] - 12s 190ms/step - loss: 0.1312 - accuracy: 0.9548 - val_loss: 0.5128 - val_accuracy: 0.8380\n\nEpoch 7/10\n\n63/63 [==============================] - 12s 191ms/step - loss: 0.0899 - accuracy: 0.9709 - val_loss: 0.5966 - val_accuracy: 0.8000\n\nEpoch 8/10\n\n63/63 [==============================] - 12s 190ms/step - loss: 0.0758 - accuracy: 0.9747 - val_loss: 0.6472 - val_accuracy: 0.8210\n\nEpoch 9/10\n\n63/63 [==============================] - 12s 190ms/step - loss: 0.0497 - accuracy: 0.9841 - val_loss: 0.6800 - val_accuracy: 0.8380\n\nEpoch 10/10\n\n63/63 [==============================] - 12s 191ms/step - loss: 0.0494 - accuracy: 0.9845 - val_loss: 0.7545 - val_accuracy: 0.8220\n"},{"output_type":"execute_result","execution_count":26,"data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f834c1e5b70>"]},"metadata":{}}]},{"cell_type":"code","source":"loss, accuracy = gru_model.evaluate(X_Test, Y_Test)\nprint(\"Test Loss:\", loss)\nprint(\"Test Accuracy:\", accuracy)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gqvnpYEu8PDB","outputId":"54c69fe1-2484-4ab6-e832-fde69a46879f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":"32/32 [==============================] - 1s 33ms/step - loss: 0.8317 - accuracy: 0.8140\n\nTest Loss: 0.8316957950592041\n\nTest Accuracy: 0.8140000104904175\n"}]},{"cell_type":"code","source":"# Get the predicted labels\ny_pred = gru_model.predict(X_Test)\ny_pred = np.argmax(y_pred, axis=1)\n\n# Convert the one-hot encoded labels back to integers\ny_true = np.argmax(Y_Test, axis=1)\n\n# Calculate precision, recall, and F1-score\nprecision = precision_score(y_true, y_pred, average='binary')\nrecall = recall_score(y_true, y_pred, average='binary')\nf1 = f1_score(y_true, y_pred, average='binary')\n\nprint(\"Precision:\", precision)\nprint(\"Recall:\", recall)\nprint(\"F1-score:\", f1)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2_ngE5wM8O_w","outputId":"4a077252-7398-4089-82e1-9857be9aaa1a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":"Precision: 0.8811188811188811\n\nRecall: 0.7368421052631579\n\nF1-score: 0.8025477707006369\n"}]},{"cell_type":"markdown","source":"## BidirectionalRNN","metadata":{"id":"QPtQaaEzXCOx"}},{"cell_type":"code","source":"","metadata":{"id":"z-231AMk8O9Q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.layers import Bidirectional\nhidden_dims=64\nbrnn_model = Sequential()\nbrnn_model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_length))\nbrnn_model.add(Dropout(0.2))\nbrnn_model.add(Bidirectional(SimpleRNN(100)))\n\nbrnn_model.add(Dense(2, activation='sigmoid'))","metadata":{"id":"7Ss13M_jAvY8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Compile the model\nbrnn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n\n# Train the model\nbrnn_model.fit(X_Train, Y_Train, validation_data=(X_Val, Y_Val), batch_size = 128, epochs=10)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qABW8_jCAvOy","outputId":"646415ae-0b7f-4c62-9c34-04db32a02bd7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":"Epoch 1/10\n\n63/63 [==============================] - 238s 4s/step - loss: 0.7012 - accuracy: 0.5034 - val_loss: 0.6896 - val_accuracy: 0.5270\n\nEpoch 2/10\n\n63/63 [==============================] - 223s 4s/step - loss: 0.6859 - accuracy: 0.5681 - val_loss: 0.6865 - val_accuracy: 0.5320\n\nEpoch 3/10\n\n63/63 [==============================] - 229s 4s/step - loss: 0.6696 - accuracy: 0.6097 - val_loss: 0.6639 - val_accuracy: 0.6100\n\nEpoch 4/10\n\n63/63 [==============================] - 225s 4s/step - loss: 0.6090 - accuracy: 0.7090 - val_loss: 0.5965 - val_accuracy: 0.6770\n\nEpoch 5/10\n\n63/63 [==============================] - 216s 3s/step - loss: 0.4662 - accuracy: 0.7890 - val_loss: 0.5223 - val_accuracy: 0.7390\n\nEpoch 6/10\n\n63/63 [==============================] - 221s 4s/step - loss: 0.3340 - accuracy: 0.8576 - val_loss: 0.4313 - val_accuracy: 0.8120\n\nEpoch 7/10\n\n63/63 [==============================] - 220s 3s/step - loss: 0.3170 - accuracy: 0.8670 - val_loss: 0.5740 - val_accuracy: 0.7370\n\nEpoch 8/10\n\n63/63 [==============================] - 222s 3s/step - loss: 0.2747 - accuracy: 0.8924 - val_loss: 0.5042 - val_accuracy: 0.7920\n\nEpoch 9/10\n\n63/63 [==============================] - 218s 3s/step - loss: 0.2755 - accuracy: 0.8923 - val_loss: 0.6809 - val_accuracy: 0.6460\n\nEpoch 10/10\n\n63/63 [==============================] - 216s 3s/step - loss: 0.3294 - accuracy: 0.8591 - val_loss: 0.7421 - val_accuracy: 0.7320\n"},{"output_type":"execute_result","execution_count":18,"data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f84a2f3d330>"]},"metadata":{}}]},{"cell_type":"code","source":"brnn_model.summary()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5rIAS0g1Mfug","outputId":"01614766-bd15-48fe-86d6-f0f122741599"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":"Model: \"sequential\"\n\n_________________________________________________________________\n\nLayer (type)                 Output Shape              Param #   \n\n=================================================================\n\nmodule_wrapper (ModuleWrappe (None, 1806, 100)         400000    \n\n_________________________________________________________________\n\ndropout (Dropout)            (None, 1806, 100)         0         \n\n_________________________________________________________________\n\nmodule_wrapper_1 (ModuleWrap (None, 200)               40200     \n\n_________________________________________________________________\n\ndense (Dense)                (None, 2)                 402       \n\n=================================================================\n\nTotal params: 440,602\n\nTrainable params: 440,602\n\nNon-trainable params: 0\n\n_________________________________________________________________\n"}]},{"cell_type":"code","source":"loss, accuracy = brnn_model.evaluate(X_Test, Y_Test)\nprint(\"Test Loss:\", loss)\nprint(\"Test Accuracy:\", accuracy)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6bVJXTrCAvGU","outputId":"5a366bb0-913b-47e9-ac16-0dce7466b533"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":"32/32 [==============================] - 8s 247ms/step - loss: 0.8522 - accuracy: 0.6970\n\nTest Loss: 0.8522228598594666\n\nTest Accuracy: 0.6970000267028809\n"}]},{"cell_type":"code","source":"# Get the predicted labels\nfrom sklearn.metrics import precision_score, recall_score, f1_score\ny_pred = brnn_model.predict(X_Test)\ny_pred = np.argmax(y_pred, axis=1)\n\n# Convert the one-hot encoded labels back to integers\ny_true = np.argmax(Y_Test, axis=1)\n\n# Calculate precision, recall, and F1-score\nprecision = precision_score(y_true, y_pred, average='binary')\nrecall = recall_score(y_true, y_pred, average='binary')\nf1 = f1_score(y_true, y_pred, average='binary')\n\nprint(\"Precision:\", precision)\nprint(\"Recall:\", recall)\nprint(\"F1-score:\", f1)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lYdFNXOlAu9v","outputId":"45458aa1-f87d-4f87-afec-2b1deca19292"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":"Precision: 0.9133858267716536\n\nRecall: 0.4522417153996101\n\nF1-score: 0.604954367666232\n"}]},{"cell_type":"code","source":"","metadata":{"id":"Ba-rSmkSAu1Y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"zn4dKuuN5PcA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## BiLSTM","metadata":{"id":"erDywSc25SzZ"}},{"cell_type":"code","source":"from tensorflow.keras.layers import  LSTM\nblstm_model = Sequential()\nblstm_model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_length))\nblstm_model.add(Bidirectional(LSTM(100)))\nblstm_model.add(Dense(2, activation='sigmoid'))\n\nblstm_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\nblstm_model.fit(X_Train, Y_Train, validation_data=(X_Test, Y_Test), batch_size = 128, epochs=10)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MZ4qR-HI5OqN","outputId":"cf9dacc3-307a-4661-b9b1-58e518ff26fa"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":"Epoch 1/10\n\n63/63 [==============================] - 16s 200ms/step - loss: 0.6715 - accuracy: 0.6219 - val_loss: 0.6277 - val_accuracy: 0.7240\n\nEpoch 2/10\n\n63/63 [==============================] - 13s 203ms/step - loss: 0.4391 - accuracy: 0.8241 - val_loss: 0.4141 - val_accuracy: 0.8390\n\nEpoch 3/10\n\n63/63 [==============================] - 12s 196ms/step - loss: 0.3066 - accuracy: 0.8766 - val_loss: 0.3955 - val_accuracy: 0.8280\n\nEpoch 4/10\n\n63/63 [==============================] - 12s 192ms/step - loss: 0.2321 - accuracy: 0.9116 - val_loss: 0.3641 - val_accuracy: 0.8630\n\nEpoch 5/10\n\n63/63 [==============================] - 12s 191ms/step - loss: 0.1844 - accuracy: 0.9340 - val_loss: 0.3678 - val_accuracy: 0.8580\n\nEpoch 6/10\n\n63/63 [==============================] - 12s 195ms/step - loss: 0.1754 - accuracy: 0.9356 - val_loss: 0.3724 - val_accuracy: 0.8650\n\nEpoch 7/10\n\n63/63 [==============================] - 12s 189ms/step - loss: 0.1410 - accuracy: 0.9501 - val_loss: 0.4542 - val_accuracy: 0.8100\n\nEpoch 8/10\n\n63/63 [==============================] - 12s 189ms/step - loss: 0.1655 - accuracy: 0.9381 - val_loss: 0.4542 - val_accuracy: 0.8550\n\nEpoch 9/10\n\n63/63 [==============================] - 12s 190ms/step - loss: 0.1111 - accuracy: 0.9628 - val_loss: 0.4522 - val_accuracy: 0.8380\n\nEpoch 10/10\n\n63/63 [==============================] - 12s 190ms/step - loss: 0.1008 - accuracy: 0.9669 - val_loss: 0.5590 - val_accuracy: 0.8620\n"},{"output_type":"execute_result","execution_count":28,"data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f84003717b0>"]},"metadata":{}}]},{"cell_type":"code","source":"blstm_model.summary()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"top7oQnyMQTD","outputId":"4ad9e590-0739-4aae-c08d-1519cda91680"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":"Model: \"sequential_4\"\n\n_________________________________________________________________\n\nLayer (type)                 Output Shape              Param #   \n\n=================================================================\n\nmodule_wrapper_7 (ModuleWrap (None, 1806, 100)         400000    \n\n_________________________________________________________________\n\nmodule_wrapper_8 (ModuleWrap (None, 200)               160800    \n\n_________________________________________________________________\n\ndense_3 (Dense)              (None, 2)                 402       \n\n=================================================================\n\nTotal params: 561,202\n\nTrainable params: 561,202\n\nNon-trainable params: 0\n\n_________________________________________________________________\n"}]},{"cell_type":"code","source":"loss, accuracy = blstm_model.evaluate(X_Test, Y_Test)\nprint(\"Test Loss:\", loss)\nprint(\"Test Accuracy:\", accuracy)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ib4S-Ycj5N46","outputId":"efd4182e-82d6-449a-e4c8-5a0bdddbe55f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":"32/32 [==============================] - 1s 44ms/step - loss: 0.5590 - accuracy: 0.8620\n\nTest Loss: 0.5590408444404602\n\nTest Accuracy: 0.8619999885559082\n"}]},{"cell_type":"code","source":"# Get the predicted labels\nfrom sklearn.metrics import precision_score, recall_score, f1_score\ny_pred = blstm_model.predict(X_Test)\ny_pred = np.argmax(y_pred, axis=1)\n\n# Convert the one-hot encoded labels back to integers\ny_true = np.argmax(Y_Test, axis=1)\n\n# Calculate precision, recall, and F1-score\nprecision = precision_score(y_true, y_pred, average='binary')\nrecall = recall_score(y_true, y_pred, average='binary')\nf1 = f1_score(y_true, y_pred, average='binary')\n\nprint(\"Precision:\", precision)\nprint(\"Recall:\", recall)\nprint(\"F1-score:\", f1)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pwYnGCCt5NKc","outputId":"558c151d-6e25-4a9a-b7e2-9978e850dcf2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":"Precision: 0.8427787934186471\n\nRecall: 0.898635477582846\n\nF1-score: 0.8698113207547171\n"}]},{"cell_type":"markdown","source":"## BiGRU","metadata":{"id":"qCk8EpBtXJl9"}},{"cell_type":"code","source":"from tensorflow.keras.layers import  GRU\nbgru_model = Sequential()\nbgru_model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_length))\nbgru_model.add(Bidirectional(GRU(32)))\nbgru_model.add(Dense(2, activation='sigmoid'))\n\nbgru_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\nbgru_model.fit(X_Train, Y_Train, validation_data=(X_Test, Y_Test), batch_size = 128, epochs=10)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XVOmTIWIAusV","outputId":"734fdd55-c04d-4010-9570-b543e83714b6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":"Epoch 1/10\n\n63/63 [==============================] - 12s 119ms/step - loss: 0.6682 - accuracy: 0.5909 - val_loss: 0.5311 - val_accuracy: 0.7410\n\nEpoch 2/10\n\n63/63 [==============================] - 6s 99ms/step - loss: 0.4003 - accuracy: 0.8224 - val_loss: 0.3943 - val_accuracy: 0.8300\n\nEpoch 3/10\n\n63/63 [==============================] - 7s 108ms/step - loss: 0.2784 - accuracy: 0.8911 - val_loss: 0.3693 - val_accuracy: 0.8520\n\nEpoch 4/10\n\n63/63 [==============================] - 6s 100ms/step - loss: 0.2258 - accuracy: 0.9141 - val_loss: 0.3980 - val_accuracy: 0.8420\n\nEpoch 5/10\n\n63/63 [==============================] - 7s 109ms/step - loss: 0.1861 - accuracy: 0.9340 - val_loss: 0.4317 - val_accuracy: 0.8270\n\nEpoch 6/10\n\n63/63 [==============================] - 6s 100ms/step - loss: 0.1563 - accuracy: 0.9475 - val_loss: 0.4854 - val_accuracy: 0.8340\n\nEpoch 7/10\n\n63/63 [==============================] - 7s 108ms/step - loss: 0.1544 - accuracy: 0.9471 - val_loss: 0.4635 - val_accuracy: 0.8420\n\nEpoch 8/10\n\n63/63 [==============================] - 8s 134ms/step - loss: 0.1304 - accuracy: 0.9566 - val_loss: 0.4693 - val_accuracy: 0.8450\n\nEpoch 9/10\n\n63/63 [==============================] - 9s 137ms/step - loss: 0.1123 - accuracy: 0.9641 - val_loss: 0.5321 - val_accuracy: 0.8370\n\nEpoch 10/10\n\n63/63 [==============================] - 7s 105ms/step - loss: 0.1009 - accuracy: 0.9686 - val_loss: 0.5256 - val_accuracy: 0.8260\n"},{"output_type":"execute_result","execution_count":24,"data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f848c02d3f0>"]},"metadata":{}}]},{"cell_type":"code","source":"loss, accuracy = bgru_model.evaluate(X_Test, Y_Test)\nprint(\"Test Loss:\", loss)\nprint(\"Test Accuracy:\", accuracy)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zVC5s8U1AukV","outputId":"7be1e1c7-2c35-4e3a-d0d3-d812e609d139"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":"32/32 [==============================] - 1s 36ms/step - loss: 0.5256 - accuracy: 0.8260\n\nTest Loss: 0.5256199836730957\n\nTest Accuracy: 0.8259999752044678\n"}]},{"cell_type":"code","source":"bgru_model.summary()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fMvXgsCzL9ab","outputId":"bd92984f-b624-4fb0-97e5-c5a20d9de69a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":"Model: \"sequential_3\"\n\n_________________________________________________________________\n\nLayer (type)                 Output Shape              Param #   \n\n=================================================================\n\nmodule_wrapper_5 (ModuleWrap (None, 1806, 100)         400000    \n\n_________________________________________________________________\n\nmodule_wrapper_6 (ModuleWrap (None, 200)               160800    \n\n_________________________________________________________________\n\ndense_2 (Dense)              (None, 2)                 402       \n\n=================================================================\n\nTotal params: 561,202\n\nTrainable params: 561,202\n\nNon-trainable params: 0\n\n_________________________________________________________________\n"}]},{"cell_type":"code","source":"# Get the predicted labels\nfrom sklearn.metrics import precision_score, recall_score, f1_score\ny_pred = bgru_model.predict(X_Test)\ny_pred = np.argmax(y_pred, axis=1)\n\n# Convert the one-hot encoded labels back to integers\ny_true = np.argmax(Y_Test, axis=1)\n\n# Calculate precision, recall, and F1-score\nprecision = precision_score(y_true, y_pred, average='binary')\nrecall = recall_score(y_true, y_pred, average='binary')\nf1 = f1_score(y_true, y_pred, average='binary')\n\nprint(\"Precision:\", precision)\nprint(\"Recall:\", recall)\nprint(\"F1-score:\", f1)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CSI19n5wAudY","outputId":"867c6b8c-f268-404d-ef85-13272e67ce4a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":"Precision: 0.8466257668711656\n\nRecall: 0.8070175438596491\n\nF1-score: 0.8263473053892216\n"}]},{"cell_type":"markdown","source":"## Stacked RNN","metadata":{"id":"vul-1TEQA7-L"}},{"cell_type":"code","source":"","metadata":{"id":"AwnVD1HK8O6d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"srnn_model = Sequential()\nsrnn_model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_length))\nsrnn_model.add(SimpleRNN(100, return_sequences=True))\nsrnn_model.add(SimpleRNN(100))\nsrnn_model.add(Dense(2, activation='sigmoid'))\nsrnn_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\nsrnn_model.fit(X_Train, Y_Train, validation_data=(X_Test, Y_Test), batch_size = 128, epochs=10)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uwy9BH81AZi3","outputId":"60adca50-f5f7-4c2e-eb2e-585ce9848b5a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":"Epoch 1/10\n\n63/63 [==============================] - 269s 4s/step - loss: 0.7123 - accuracy: 0.5214 - val_loss: 0.6805 - val_accuracy: 0.5630\n\nEpoch 2/10\n\n63/63 [==============================] - 259s 4s/step - loss: 0.6307 - accuracy: 0.6574 - val_loss: 0.6162 - val_accuracy: 0.6560\n\nEpoch 3/10\n\n63/63 [==============================] - 259s 4s/step - loss: 0.5090 - accuracy: 0.7434 - val_loss: 0.6286 - val_accuracy: 0.6370\n\nEpoch 4/10\n\n63/63 [==============================] - 255s 4s/step - loss: 0.4828 - accuracy: 0.7751 - val_loss: 0.4782 - val_accuracy: 0.7740\n\nEpoch 5/10\n\n63/63 [==============================] - 256s 4s/step - loss: 0.3922 - accuracy: 0.8328 - val_loss: 0.4669 - val_accuracy: 0.7840\n\nEpoch 6/10\n\n63/63 [==============================] - 257s 4s/step - loss: 0.3175 - accuracy: 0.8687 - val_loss: 0.4696 - val_accuracy: 0.8060\n\nEpoch 7/10\n\n63/63 [==============================] - 257s 4s/step - loss: 0.2749 - accuracy: 0.8864 - val_loss: 0.5280 - val_accuracy: 0.7800\n\nEpoch 8/10\n\n63/63 [==============================] - 253s 4s/step - loss: 0.2006 - accuracy: 0.9219 - val_loss: 0.5664 - val_accuracy: 0.7750\n\nEpoch 9/10\n\n63/63 [==============================] - 256s 4s/step - loss: 0.1648 - accuracy: 0.9413 - val_loss: 0.6482 - val_accuracy: 0.7730\n\nEpoch 10/10\n\n63/63 [==============================] - 254s 4s/step - loss: 0.1315 - accuracy: 0.9532 - val_loss: 0.6834 - val_accuracy: 0.7630\n"},{"output_type":"execute_result","execution_count":36,"data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f83df7623e0>"]},"metadata":{}}]},{"cell_type":"code","source":"srnn_model.summary()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zJ8fveo8LJ44","outputId":"8f888c58-12a7-453b-c815-afb3b8d477a3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":"Model: \"sequential_7\"\n\n_________________________________________________________________\n\nLayer (type)                 Output Shape              Param #   \n\n=================================================================\n\nmodule_wrapper_15 (ModuleWra (None, 1806, 100)         400000    \n\n_________________________________________________________________\n\nmodule_wrapper_16 (ModuleWra (None, 1806, 100)         20100     \n\n_________________________________________________________________\n\nmodule_wrapper_17 (ModuleWra (None, 100)               20100     \n\n_________________________________________________________________\n\ndense_6 (Dense)              (None, 2)                 202       \n\n=================================================================\n\nTotal params: 440,402\n\nTrainable params: 440,402\n\nNon-trainable params: 0\n\n_________________________________________________________________\n"}]},{"cell_type":"code","source":"loss, accuracy = srnn_model.evaluate(X_Test, Y_Test)\nprint(\"Test Loss:\", loss)\nprint(\"Test Accuracy:\", accuracy)\n# Get the predicted labels\nfrom sklearn.metrics import precision_score, recall_score, f1_score\ny_pred = srnn_model.predict(X_Test)\ny_pred = np.argmax(y_pred, axis=1)\n\n# Convert the one-hot encoded labels back to integers\ny_true = np.argmax(Y_Test, axis=1)\n\n# Calculate precision, recall, and F1-score\nprecision = precision_score(y_true, y_pred, average='binary')\nrecall = recall_score(y_true, y_pred, average='binary')\nf1 = f1_score(y_true, y_pred, average='binary')\n\nprint(\"Precision:\", precision)\nprint(\"Recall:\", recall)\nprint(\"F1-score:\", f1)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0AXNWSeS7s_l","outputId":"6721dcde-8000-4ef5-c44d-57f74c2c1cf1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":"32/32 [==============================] - 10s 303ms/step - loss: 0.6834 - accuracy: 0.7630\n\nTest Loss: 0.6833871603012085\n\nTest Accuracy: 0.7630000114440918\n\nPrecision: 0.7875\n\nRecall: 0.7368421052631579\n\nF1-score: 0.7613293051359517\n"}]},{"cell_type":"markdown","source":"## Stacked LSTM","metadata":{"id":"1dZCSOro8StJ"}},{"cell_type":"code","source":"slstm_model = Sequential()\nslstm_model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_length))\nslstm_model.add(LSTM(100, return_sequences=True))\nslstm_model.add(LSTM(100))\nslstm_model.add(Dense(2, activation='sigmoid'))\nslstm_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\nslstm_model.fit(X_Train, Y_Train, validation_data=(X_Test, Y_Test), batch_size = 128, epochs=10)\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qNIBLqHU8W9x","outputId":"46d38ab0-f3a3-4c14-c07f-5c8a4a40dd5f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":"Epoch 1/10\n\n63/63 [==============================] - 20s 254ms/step - loss: 0.5499 - accuracy: 0.7036 - val_loss: 0.4290 - val_accuracy: 0.7930\n\nEpoch 2/10\n\n63/63 [==============================] - 13s 202ms/step - loss: 0.2868 - accuracy: 0.8865 - val_loss: 0.3327 - val_accuracy: 0.8580\n\nEpoch 3/10\n\n63/63 [==============================] - 14s 229ms/step - loss: 0.2036 - accuracy: 0.9227 - val_loss: 0.3633 - val_accuracy: 0.8720\n\nEpoch 4/10\n\n63/63 [==============================] - 12s 194ms/step - loss: 0.1455 - accuracy: 0.9474 - val_loss: 0.3710 - val_accuracy: 0.8500\n\nEpoch 5/10\n\n63/63 [==============================] - 12s 193ms/step - loss: 0.1175 - accuracy: 0.9576 - val_loss: 0.5106 - val_accuracy: 0.8500\n\nEpoch 6/10\n\n63/63 [==============================] - 13s 209ms/step - loss: 0.0751 - accuracy: 0.9737 - val_loss: 0.6201 - val_accuracy: 0.8530\n\nEpoch 7/10\n\n63/63 [==============================] - 13s 199ms/step - loss: 0.0522 - accuracy: 0.9826 - val_loss: 0.5837 - val_accuracy: 0.8540\n\nEpoch 8/10\n\n63/63 [==============================] - 12s 192ms/step - loss: 0.0398 - accuracy: 0.9876 - val_loss: 0.7217 - val_accuracy: 0.8520\n\nEpoch 9/10\n\n63/63 [==============================] - 12s 195ms/step - loss: 0.0211 - accuracy: 0.9933 - val_loss: 0.7570 - val_accuracy: 0.8260\n\nEpoch 10/10\n\n63/63 [==============================] - 12s 192ms/step - loss: 0.0282 - accuracy: 0.9908 - val_loss: 0.7676 - val_accuracy: 0.8460\n"},{"output_type":"execute_result","execution_count":31,"data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f83fafb4cd0>"]},"metadata":{}}]},{"cell_type":"code","source":"slstm_model.summary()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gY2244aoLUgI","outputId":"626caaaf-1548-47b7-b869-3bb29614b9a1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":"Model: \"sequential_5\"\n\n_________________________________________________________________\n\nLayer (type)                 Output Shape              Param #   \n\n=================================================================\n\nmodule_wrapper_9 (ModuleWrap (None, 1806, 100)         400000    \n\n_________________________________________________________________\n\nmodule_wrapper_10 (ModuleWra (None, 1806, 100)         80400     \n\n_________________________________________________________________\n\nmodule_wrapper_11 (ModuleWra (None, 100)               80400     \n\n_________________________________________________________________\n\ndense_4 (Dense)              (None, 2)                 202       \n\n=================================================================\n\nTotal params: 561,002\n\nTrainable params: 561,002\n\nNon-trainable params: 0\n\n_________________________________________________________________\n"}]},{"cell_type":"code","source":"loss, accuracy = slstm_model.evaluate(X_Test, Y_Test)\nprint(\"Test Loss:\", loss)\nprint(\"Test Accuracy:\", accuracy)\n# Get the predicted labels\nfrom sklearn.metrics import precision_score, recall_score, f1_score\ny_pred = slstm_model.predict(X_Test)\ny_pred = np.argmax(y_pred, axis=1)\n\n# Convert the one-hot encoded labels back to integers\ny_true = np.argmax(Y_Test, axis=1)\n\n# Calculate precision, recall, and F1-score\nprecision = precision_score(y_true, y_pred, average='binary')\nrecall = recall_score(y_true, y_pred, average='binary')\nf1 = f1_score(y_true, y_pred, average='binary')\n\nprint(\"Precision:\", precision)\nprint(\"Recall:\", recall)\nprint(\"F1-score:\", f1)\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"COhKN_5Y9f24","outputId":"5db66811-6683-4d98-eb68-e3cc35adaaa4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":"32/32 [==============================] - 1s 45ms/step - loss: 0.7676 - accuracy: 0.8460\n\nTest Loss: 0.7676162719726562\n\nTest Accuracy: 0.8460000157356262\n\nPrecision: 0.8499025341130604\n\nRecall: 0.8499025341130604\n\nF1-score: 0.8499025341130604\n"}]},{"cell_type":"code","source":"","metadata":{"id":"H_gOL-nU_Fdh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"NjmfJLVc_Ehb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sgru_model = Sequential()\nsgru_model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_length))\nsgru_model.add(GRU(100, return_sequences=True))\nsgru_model.add(GRU(100))\nsgru_model.add(Dense(2, activation='sigmoid'))\nsgru_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\nsgru_model.fit(X_Train, Y_Train, validation_data=(X_Test, Y_Test), batch_size = 128, epochs=10)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rwQAMNUy_Dma","outputId":"043dde68-0542-4d01-f430-3ff3c9502533"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":"Epoch 1/10\n\n63/63 [==============================] - 15s 184ms/step - loss: 0.5979 - accuracy: 0.6554 - val_loss: 0.4316 - val_accuracy: 0.8080\n\nEpoch 2/10\n\n63/63 [==============================] - 11s 177ms/step - loss: 0.3968 - accuracy: 0.8225 - val_loss: 0.4611 - val_accuracy: 0.7880\n\nEpoch 3/10\n\n63/63 [==============================] - 15s 232ms/step - loss: 0.2793 - accuracy: 0.8864 - val_loss: 0.4265 - val_accuracy: 0.8230\n\nEpoch 4/10\n\n63/63 [==============================] - 11s 178ms/step - loss: 0.1932 - accuracy: 0.9273 - val_loss: 0.4360 - val_accuracy: 0.8540\n\nEpoch 5/10\n\n63/63 [==============================] - 11s 174ms/step - loss: 0.1431 - accuracy: 0.9470 - val_loss: 0.6317 - val_accuracy: 0.8360\n\nEpoch 6/10\n\n63/63 [==============================] - 11s 173ms/step - loss: 0.0864 - accuracy: 0.9720 - val_loss: 0.6682 - val_accuracy: 0.8140\n\nEpoch 7/10\n\n63/63 [==============================] - 11s 174ms/step - loss: 0.0685 - accuracy: 0.9780 - val_loss: 0.7361 - val_accuracy: 0.8070\n\nEpoch 8/10\n\n63/63 [==============================] - 11s 175ms/step - loss: 0.0443 - accuracy: 0.9852 - val_loss: 1.0094 - val_accuracy: 0.8140\n\nEpoch 9/10\n\n63/63 [==============================] - 11s 175ms/step - loss: 0.0366 - accuracy: 0.9860 - val_loss: 1.0208 - val_accuracy: 0.8030\n\nEpoch 10/10\n\n63/63 [==============================] - 11s 175ms/step - loss: 0.0252 - accuracy: 0.9909 - val_loss: 1.1551 - val_accuracy: 0.7870\n"},{"output_type":"execute_result","execution_count":33,"data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f83faf93c10>"]},"metadata":{}}]},{"cell_type":"code","source":"sgru_model.summary()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jV6u93NlLgWn","outputId":"ab9abfab-f51e-4af0-aa5c-df278a14e627"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":"Model: \"sequential_6\"\n\n_________________________________________________________________\n\nLayer (type)                 Output Shape              Param #   \n\n=================================================================\n\nmodule_wrapper_12 (ModuleWra (None, 1806, 100)         400000    \n\n_________________________________________________________________\n\nmodule_wrapper_13 (ModuleWra (None, 1806, 100)         60600     \n\n_________________________________________________________________\n\nmodule_wrapper_14 (ModuleWra (None, 100)               60600     \n\n_________________________________________________________________\n\ndense_5 (Dense)              (None, 2)                 202       \n\n=================================================================\n\nTotal params: 521,402\n\nTrainable params: 521,402\n\nNon-trainable params: 0\n\n_________________________________________________________________\n"}]},{"cell_type":"code","source":"","metadata":{"id":"7A32seY0LfUU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss, accuracy = sgru_model.evaluate(X_Test, Y_Test)\nprint(\"Test Loss:\", loss)\nprint(\"Test Accuracy:\", accuracy)\n# Get the predicted labels\nfrom sklearn.metrics import precision_score, recall_score, f1_score\ny_pred = sgru_model.predict(X_Test)\ny_pred = np.argmax(y_pred, axis=1)\n\n# Convert the one-hot encoded labels back to integers\ny_true = np.argmax(Y_Test, axis=1)\n\n# Calculate precision, recall, and F1-score\nprecision = precision_score(y_true, y_pred, average='binary')\nrecall = recall_score(y_true, y_pred, average='binary')\nf1 = f1_score(y_true, y_pred, average='binary')\n\nprint(\"Precision:\", precision)\nprint(\"Recall:\", recall)\nprint(\"F1-score:\", f1)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YRBKJ_Jl_Cr5","outputId":"2403a268-c05a-4e2f-deb2-9aff5fa2ae17"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":"32/32 [==============================] - 2s 73ms/step - loss: 1.1551 - accuracy: 0.7870\n\nTest Loss: 1.1550843715667725\n\nTest Accuracy: 0.7870000004768372\n\nPrecision: 0.8138075313807531\n\nRecall: 0.7582846003898636\n\nF1-score: 0.7850655903128154\n"}]},{"cell_type":"code","source":"","metadata":{"id":"BZ-u3dvO_Bv5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tabulate import tabulate\n\nTable = [\n    [\"Accuracy Score:\", 0.75,0.826,0.814,0.697,0.86199,0.826,0.763,0.846,0.787],\n    ['Precision',0.7573,0.84809,0.881118,0.91338,0.84277879,0.846625,0.7875,0.8499,0.8138],\n    ['recall',0.754385,0.80506822,0.73684,0.45224,0.898635,0.80701,0.73684,0.8499,0.75828],\n    ['F1-score',0.755859,0.826,0.80254,0.604954,0.869811,0.826347,0.761329,0.8499,0.785066]\n]\n\n# Create header\nhead = [\"Model\", \"RNN\", \"LSTM\", \"GRU\", \"Stacked_RNN\", \"Stacked_LSTM\",\n        \"Stacked_GRU\", \"Bi_RNN\", \"Bi_LSTM\", \"Bi_GRU\"]\n\n# Display table\nprint(tabulate(Table, headers=head, tablefmt=\"grid\"))","metadata":{"id":"Z6Fdl-PZ_A2W","execution":{"iopub.status.busy":"2023-05-15T01:59:24.997212Z","iopub.execute_input":"2023-05-15T01:59:24.997559Z","iopub.status.idle":"2023-05-15T01:59:25.040404Z","shell.execute_reply.started":"2023-05-15T01:59:24.997530Z","shell.execute_reply":"2023-05-15T01:59:25.039432Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"+-----------------+----------+----------+----------+---------------+----------------+---------------+----------+-----------+----------+\n| Model           |      RNN |     LSTM |      GRU |   Stacked_RNN |   Stacked_LSTM |   Stacked_GRU |   Bi_RNN |   Bi_LSTM |   Bi_GRU |\n+=================+==========+==========+==========+===============+================+===============+==========+===========+==========+\n| Accuracy Score: | 0.75     | 0.826    | 0.814    |      0.697    |       0.86199  |      0.826    | 0.763    |    0.846  | 0.787    |\n+-----------------+----------+----------+----------+---------------+----------------+---------------+----------+-----------+----------+\n| Precision       | 0.7573   | 0.84809  | 0.881118 |      0.91338  |       0.842779 |      0.846625 | 0.7875   |    0.8499 | 0.8138   |\n+-----------------+----------+----------+----------+---------------+----------------+---------------+----------+-----------+----------+\n| recall          | 0.754385 | 0.805068 | 0.73684  |      0.45224  |       0.898635 |      0.80701  | 0.73684  |    0.8499 | 0.75828  |\n+-----------------+----------+----------+----------+---------------+----------------+---------------+----------+-----------+----------+\n| F1-score        | 0.755859 | 0.826    | 0.80254  |      0.604954 |       0.869811 |      0.826347 | 0.761329 |    0.8499 | 0.785066 |\n+-----------------+----------+----------+----------+---------------+----------------+---------------+----------+-----------+----------+\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"id":"x5gtgB7MHfMq"},"execution_count":null,"outputs":[]}]}